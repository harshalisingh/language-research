#Date : 07/11/2016
library(ggplot2)
library(plyr)
library(wordcloud)
library(RColorBrewer)
library(stringr)
setwd("~/ParseHubData/Source_Data")
list <-read.csv("technologies_list.csv", header=TRUE, stringsAsFactors = TRUE)
setwd("~/ParseHubData/Source_Data/telecom")
files = list.files(pattern="results.csv")
freq_total <-matrix(nrow=length(list$Language), ncol=1, 0)
pdf(paste("Plot.pdf", date(), sep = "_"))
for(f in 1:length(files)){
filename = files[f]
company = strsplit(filename, "_")[[1]][1]
data = read.csv(filename, header=FALSE, stringsAsFactors = FALSE)
df <- data.frame(A = data$V1, B = data$V2)
df$D <- paste(df$A, df$B, sep=" ")
df<-df$D
##Preparing the text for Sentiment Analysis
Sys.setlocale('LC_ALL','C')
# replace ++ and #
text <- gsub('++', "pp", df, fixed = TRUE)
text <- gsub("#", "sharp", text)
# remove punctuation
text <- gsub("[[:punct:]]", " ", text)
# remove html links
text <- gsub("http\\w+", "", text)
# remove unnecessary spaces
text <- gsub("^\\s+|\\s+$", "", text)
# define "tolower error handling" function
try.tolower = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# lower case using try.error with sapply
text <- sapply(text, try.tolower)
list$Variation <- sapply(list$Variation, try.tolower)
# remove NAs in some_txt
text <- text[!is.na(text)]
names(text) <- NULL
freq<-matrix(nrow=length(list$Language), ncol=1, 0)
for (i in 1:length(list$Language))
{
inc <- 0
#iterate over each variation
k <- strsplit(list$Variation[i], ",")
for (j in 1:length(k[[1]])){
c <- count(grep(paste("\\b", k[[1]][j], "\\b", sep=""), text))
inc <- inc + length(c$x)
}
freq[i,] <- inc
freq_total[i,] <- freq_total[i] + freq[i]
}
list$freq <- freq
list$freq_total <- freq_total
subset_c <- subset(list, freq > 1)
sorted_c <- arrange(subset_c,freq, decreasing=TRUE)
if(nrow(sorted_c) < 10){
top_10 <- sorted_c[,]
}
else { top_10 <- sorted_c[1:10,]}
p <- ggplot(data=top_10, aes(x=Language, y=freq)) +
geom_bar(stat="identity", width = 0.5, fill="steelblue") +
#ggtitle(paste("Telecom Company #", f, sep="")) +
ggtitle(paste(company, sep="")) +
xlab("") + ylab("Number of Job Postings") +
#scale_x_discrete(labels = function(x) str_wrap(top_10$Language, width = 6)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(p)
}
subset_t <- subset(list, freq_total > 1)
sorted_t <- arrange(subset_t,freq_total, decreasing=TRUE)
q <- ggplot(data=sorted_t, aes(x=Language, y=freq)) +
geom_bar(stat="identity", width = 0.5, fill="steelblue") +
#ggtitle(paste("Telecom Company #", f, sep="")) +
ggtitle(paste(company, sep="")) +
xlab("") + ylab("Number of Job Postings") +
#scale_x_discrete(labels = function(x) str_wrap(top_10$Language, width = 6)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(q)
dev.off()
q
#Date : 07/11/2016
library(ggplot2)
library(plyr)
library(wordcloud)
library(RColorBrewer)
library(stringr)
setwd("~/ParseHubData/Source_Data")
list <-read.csv("technologies_list.csv", header=TRUE, stringsAsFactors = TRUE)
setwd("~/ParseHubData/Source_Data/telecom")
files = list.files(pattern="results.csv")
freq_total <-matrix(nrow=length(list$Language), ncol=1, 0)
pdf(paste("Plot.pdf", date(), sep = "_"))
for(f in 1:length(files)){
filename = files[f]
company = strsplit(filename, "_")[[1]][1]
data = read.csv(filename, header=FALSE, stringsAsFactors = FALSE)
df <- data.frame(A = data$V1, B = data$V2)
df$D <- paste(df$A, df$B, sep=" ")
df<-df$D
##Preparing the text for Sentiment Analysis
Sys.setlocale('LC_ALL','C')
# replace ++ and #
text <- gsub('++', "pp", df, fixed = TRUE)
text <- gsub("#", "sharp", text)
# remove punctuation
text <- gsub("[[:punct:]]", " ", text)
# remove html links
text <- gsub("http\\w+", "", text)
# remove unnecessary spaces
text <- gsub("^\\s+|\\s+$", "", text)
# define "tolower error handling" function
try.tolower = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# lower case using try.error with sapply
text <- sapply(text, try.tolower)
list$Variation <- sapply(list$Variation, try.tolower)
# remove NAs in some_txt
text <- text[!is.na(text)]
names(text) <- NULL
freq<-matrix(nrow=length(list$Language), ncol=1, 0)
for (i in 1:length(list$Language))
{
inc <- 0
#iterate over each variation
k <- strsplit(list$Variation[i], ",")
for (j in 1:length(k[[1]])){
c <- count(grep(paste("\\b", k[[1]][j], "\\b", sep=""), text))
inc <- inc + length(c$x)
}
freq[i,] <- inc
freq_total[i,] <- freq_total[i] + freq[i]
}
list$freq <- freq
list$freq_total <- freq_total
subset_c <- subset(list, freq > 1)
sorted_c <- arrange(subset_c,freq, decreasing=TRUE)
if(nrow(sorted_c) < 10){
top_10 <- sorted_c[,]
}
else { top_10 <- sorted_c[1:10,]}
p <- ggplot(data=top_10, aes(x=Language, y=freq)) +
geom_bar(stat="identity", width = 0.5, fill="steelblue") +
#ggtitle(paste("Telecom Company #", f, sep="")) +
ggtitle(paste(company, sep="")) +
xlab("") + ylab("Number of Job Postings") +
#scale_x_discrete(labels = function(x) str_wrap(top_10$Language, width = 6)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(p)
}
subset_t <- subset(list, freq_total > 1)
sorted_t <- arrange(subset_t,freq_total, decreasing=TRUE)
top10_t <- sorted_c[1:10,]
q <- ggplot(data=top10_t, aes(x=Language, y=freq)) +
geom_bar(stat="identity", width = 0.5, fill="steelblue") +
#ggtitle(paste("Telecom Company #", f, sep="")) +
ggtitle(paste(company, sep="")) +
xlab("") + ylab("Number of Job Postings") +
#scale_x_discrete(labels = function(x) str_wrap(top_10$Language, width = 6)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
q
print(q)
q
subset_t <- subset(list, freq_total > 1)
sorted_t <- arrange(subset_t,freq_total, decreasing=TRUE)
top10_t <- sorted_t[1:10,]
q <- ggplot(data=top10_t, aes(x=Language, y=freq)) +
geom_bar(stat="identity", width = 0.5, fill="steelblue") +
#ggtitle(paste("Telecom Company #", f, sep="")) +
ggtitle(paste(company, sep="")) +
xlab("") + ylab("Number of Job Postings") +
#scale_x_discrete(labels = function(x) str_wrap(top_10$Language, width = 6)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
q
print(q)
View(sorted_t)
q <- ggplot(data=top10_t, aes(x=Language, y=freq_total)) +
geom_bar(stat="identity", width = 0.5, fill="steelblue") +
#ggtitle(paste("Telecom Company #", f, sep="")) +
ggtitle(paste(company, sep="")) +
xlab("") + ylab("Number of Job Postings") +
#scale_x_discrete(labels = function(x) str_wrap(top_10$Language, width = 6)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
q
print(q)
q <- ggplot(data=top10_t, aes(x=Language, y=freq_total)) +
geom_bar(stat="identity", width = 0.5, fill="steelblue") +
#ggtitle(paste("Telecom Company #", f, sep="")) +
ggtitle(paste("Telecom Industry", sep="")) +
xlab("") + ylab("Number of Job Postings") +
#scale_x_discrete(labels = function(x) str_wrap(top_10$Language, width = 6)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
q
print(q)
View(list)
dev.off()
q
q
print(q)
q
#Date : 07/11/2016
library(ggplot2)
library(plyr)
library(wordcloud)
library(RColorBrewer)
library(stringr)
setwd("~/ParseHubData/Source_Data")
list <-read.csv("technologies_list.csv", header=TRUE, stringsAsFactors = TRUE)
setwd("~/ParseHubData/Source_Data/telecom")
files = list.files(pattern="results.csv")
freq_total <-matrix(nrow=length(list$Language), ncol=1, 0)
pdf(paste("Plot.pdf", date(), sep = "_"))
for(f in 1:length(files)){
filename = files[f]
company = strsplit(filename, "_")[[1]][1]
data = read.csv(filename, header=FALSE, stringsAsFactors = FALSE)
df <- data.frame(A = data$V1, B = data$V2)
df$D <- paste(df$A, df$B, sep=" ")
df<-df$D
##Preparing the text for Sentiment Analysis
Sys.setlocale('LC_ALL','C')
# replace ++ and #
text <- gsub('++', "pp", df, fixed = TRUE)
text <- gsub("#", "sharp", text)
# remove punctuation
text <- gsub("[[:punct:]]", " ", text)
# remove html links
text <- gsub("http\\w+", "", text)
# remove unnecessary spaces
text <- gsub("^\\s+|\\s+$", "", text)
# define "tolower error handling" function
try.tolower = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# lower case using try.error with sapply
text <- sapply(text, try.tolower)
list$Variation <- sapply(list$Variation, try.tolower)
# remove NAs in some_txt
text <- text[!is.na(text)]
names(text) <- NULL
freq<-matrix(nrow=length(list$Language), ncol=1, 0)
for (i in 1:length(list$Language))
{
inc <- 0
#iterate over each variation
k <- strsplit(list$Variation[i], ",")
for (j in 1:length(k[[1]])){
c <- count(grep(paste("\\b", k[[1]][j], "\\b", sep=""), text))
inc <- inc + length(c$x)
}
freq[i,] <- inc
freq_total[i,] <- freq_total[i] + freq[i]
}
list$freq <- freq
list$freq_total <- freq_total
subset_c <- subset(list, freq > 1)
sorted_c <- arrange(subset_c,freq, decreasing=TRUE)
if(nrow(sorted_c) < 10){
top_10 <- sorted_c[,]
}
else { top_10 <- sorted_c[1:10,]}
p <- ggplot(data=top_10, aes(x=Language, y=freq)) +
geom_bar(stat="identity", width = 0.5, fill="steelblue") +
#ggtitle(paste("Telecom Company #", f, sep="")) +
ggtitle(paste(company, sep="")) +
xlab("") + ylab("Number of Job Postings") +
#scale_x_discrete(labels = function(x) str_wrap(top_10$Language, width = 6)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(p)
}
subset_t <- subset(list, freq_total > 1)
sorted_t <- arrange(subset_t,freq_total, decreasing=TRUE)
top10_t <- sorted_t[1:10,]
q <- ggplot(data=top10_t, aes(x=Language, y=freq_total)) +
geom_bar(stat="identity", width = 0.5, fill="steelblue") +
#ggtitle(paste("Telecom Company #", f, sep="")) +
ggtitle(paste("Telecom Industry", sep="")) +
xlab("") + ylab("Number of Job Postings") +
#scale_x_discrete(labels = function(x) str_wrap(top_10$Language, width = 6)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
q
print(q)
p
q
#Date : 07/11/2016
library(ggplot2)
library(plyr)
library(wordcloud)
library(RColorBrewer)
library(stringr)
setwd("~/ParseHubData/Source_Data")
list <-read.csv("technologies_list.csv", header=TRUE, stringsAsFactors = TRUE)
setwd("~/ParseHubData/Source_Data/telecom")
files = list.files(pattern="results.csv")
freq_total <-matrix(nrow=length(list$Language), ncol=1, 0)
pdf(paste("Plot.pdf", date(), sep = "_"))
for(f in 1:length(files)){
filename = files[f]
company = strsplit(filename, "_")[[1]][1]
data = read.csv(filename, header=FALSE, stringsAsFactors = FALSE)
df <- data.frame(A = data$V1, B = data$V2)
df$D <- paste(df$A, df$B, sep=" ")
df<-df$D
##Preparing the text for Sentiment Analysis
Sys.setlocale('LC_ALL','C')
# replace ++ and #
text <- gsub('++', "pp", df, fixed = TRUE)
text <- gsub("#", "sharp", text)
# remove punctuation
text <- gsub("[[:punct:]]", " ", text)
# remove html links
text <- gsub("http\\w+", "", text)
# remove unnecessary spaces
text <- gsub("^\\s+|\\s+$", "", text)
# define "tolower error handling" function
try.tolower = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# lower case using try.error with sapply
text <- sapply(text, try.tolower)
list$Variation <- sapply(list$Variation, try.tolower)
# remove NAs in some_txt
text <- text[!is.na(text)]
names(text) <- NULL
freq<-matrix(nrow=length(list$Language), ncol=1, 0)
for (i in 1:length(list$Language))
{
inc <- 0
#iterate over each variation
k <- strsplit(list$Variation[i], ",")
for (j in 1:length(k[[1]])){
c <- count(grep(paste("\\b", k[[1]][j], "\\b", sep=""), text))
inc <- inc + length(c$x)
}
freq[i,] <- inc
freq_total[i,] <- freq_total[i] + freq[i]
}
list$freq <- freq
list$freq_total <- freq_total
subset_c <- subset(list, freq > 1)
sorted_c <- arrange(subset_c,freq, decreasing=TRUE)
if(nrow(sorted_c) < 10){
top_10 <- sorted_c[,]
}
else { top_10 <- sorted_c[1:10,]}
p <- ggplot(data=top_10, aes(x=Language, y=freq)) +
geom_bar(stat="identity", width = 0.5, fill="steelblue") +
#ggtitle(paste("Telecom Company #", f, sep="")) +
ggtitle(paste(company, sep="")) +
xlab("") + ylab("Number of Job Postings") +
#scale_x_discrete(labels = function(x) str_wrap(top_10$Language, width = 6)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(p)
}
p
subset_t <- subset(list, freq_total > 1)
sorted_t <- arrange(subset_t,freq_total, decreasing=TRUE)
top10_t <- sorted_t[1:10,]
q <- ggplot(data=top10_t, aes(x=Language, y=freq_total)) +
geom_bar(stat="identity", width = 0.5, fill="steelblue") +
#ggtitle(paste("Telecom Company #", f, sep="")) +
ggtitle(paste("Telecom Industry", sep="")) +
xlab("") + ylab("Number of Job Postings") +
#scale_x_discrete(labels = function(x) str_wrap(top_10$Language, width = 6)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
q
print(q)
dev.off()
dev.off()
q
getwd()
q
print(q)
#Date : 07/11/2016
library(ggplot2)
library(plyr)
library(wordcloud)
library(RColorBrewer)
library(stringr)
setwd("~/ParseHubData/Source_Data")
list <-read.csv("technologies_list.csv", header=TRUE, stringsAsFactors = TRUE)
setwd("~/ParseHubData/Source_Data/telecom")
files = list.files(pattern="results.csv")
freq_total <-matrix(nrow=length(list$Language), ncol=1, 0)
pdf(paste("Plot.pdf", date(), sep = "_"))
for(f in 1:length(files)){
filename = files[f]
company = strsplit(filename, "_")[[1]][1]
data = read.csv(filename, header=FALSE, stringsAsFactors = FALSE)
df <- data.frame(A = data$V1, B = data$V2)
df$D <- paste(df$A, df$B, sep=" ")
df<-df$D
##Preparing the text for Sentiment Analysis
Sys.setlocale('LC_ALL','C')
# replace ++ and #
text <- gsub('++', "pp", df, fixed = TRUE)
text <- gsub("#", "sharp", text)
# remove punctuation
text <- gsub("[[:punct:]]", " ", text)
# remove html links
text <- gsub("http\\w+", "", text)
# remove unnecessary spaces
text <- gsub("^\\s+|\\s+$", "", text)
# define "tolower error handling" function
try.tolower = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# lower case using try.error with sapply
text <- sapply(text, try.tolower)
list$Variation <- sapply(list$Variation, try.tolower)
# remove NAs in some_txt
text <- text[!is.na(text)]
names(text) <- NULL
freq<-matrix(nrow=length(list$Language), ncol=1, 0)
for (i in 1:length(list$Language))
{
inc <- 0
#iterate over each variation
k <- strsplit(list$Variation[i], ",")
for (j in 1:length(k[[1]])){
c <- count(grep(paste("\\b", k[[1]][j], "\\b", sep=""), text))
inc <- inc + length(c$x)
}
freq[i,] <- inc
freq_total[i,] <- freq_total[i] + freq[i]
}
list$freq <- freq
list$freq_total <- freq_total
subset_c <- subset(list, freq > 1)
sorted_c <- arrange(subset_c,freq, decreasing=TRUE)
if(nrow(sorted_c) < 10){
top_10 <- sorted_c[,]
}
else { top_10 <- sorted_c[1:10,]}
p <- ggplot(data=top_10, aes(x=Language, y=freq)) +
geom_bar(stat="identity", width = 0.5, fill="steelblue") +
#ggtitle(paste("Telecom Company #", f, sep="")) +
ggtitle(paste(company, sep="")) +
xlab("") + ylab("Number of Job Postings") +
#scale_x_discrete(labels = function(x) str_wrap(top_10$Language, width = 6)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
print(p)
}
subset_t <- subset(list, freq_total > 1)
sorted_t <- arrange(subset_t,freq_total, decreasing=TRUE)
top10_t <- sorted_t[1:10,]
q <- ggplot(data=top10_t, aes(x=Language, y=freq_total)) +
geom_bar(stat="identity", width = 0.5, fill="steelblue") +
#ggtitle(paste("Telecom Company #", f, sep="")) +
ggtitle(paste("Telecom Industry", sep="")) +
xlab("") + ylab("Number of Job Postings") +
#scale_x_discrete(labels = function(x) str_wrap(top_10$Language, width = 6)) +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
q
print(q)
dev.off()
q
dev.off
dev.off()
q
